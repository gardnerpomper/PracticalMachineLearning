# Prediction of exercise type from instrumentation readings

writeup for Coursera's Practical Machine Learning Final Project

# Data

Data was provided for the exercise from the following url: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

It consists of timestamped measurements from varying instruments,
along with a user name and the type of exercise they were doing at the
time. This will provide both the training and test data for this
analysis.

## Loading

The data is loaded from the file, which was copied to the current directory:

```{r}
library(caret)
library(doMC)

registerDoMC(3) # allow 2 cores for processing
set.seed(12345)
raw.df <- read.csv("pml-training.csv",na.strings=c("NA",""))
```

## Preprocessing

There are two types of events in the file. One is the raw collection
of instrumentation readings. The other is the statistical information
for a 1 second time period of the raw data. This statistical
information is marked with a field named "new_window" and a value of
"yes". The analysis is done on only the raw data, since the
statistical information (mean, max, etc) is of a different type that
the bulk of the information. This code restricts to just the raw
information:

```{r}
whole.window <- raw.df$new_window != "yes"
window.df <- raw.df[whole.window,c(160,8:159)]
##
## make sure all the values are numeric, not factors
##
window.df[,-c(1)] <- sapply(window.df[,-c(1)],function(x){ as.numeric(as.character(x))})
##
## figure out which columns have values in them and eliminate the rest
##
nsv <- nearZeroVar(window.df,saveMetrics=TRUE)
window.df <- window.df[,nsv$nzv == FALSE]
```

## Splitting into training and testing datasets

In order to do cross validation, the data is split into 2 sets; one
for training the model and one for testing the accuracy. Because there
are many observations and the model chosen (random forest) is
computationally expensive, the training set is restricted to 3000
observations.

```{r}
inTrain <- sample(nrow(window.df),3000)

training.raw <- window.df[inTrain,]
testing.raw <- window.df[-inTrain,]
```

## Imputing missing values

The observations have occasional missing values, which messed up the learning algorithsm. The missing values are imputed using the knn preprocess method:

```{r}
predictors <- subset(training.raw,select=-c(classe))
preObj <- preProcess(predictors,method="knnImpute")
training <- predict(preObj,predictors)
training$classe <- training.raw$classe

testing <- predict(preObj,subset(testing.raw,select=-c(classe)))
testing$classe <- testing.raw$classe
```

# Modelling

Several modelling approaches were taken

## Tree classifier

```{r}
modFit <- train(classe ~ ., method="rpart",data=training)
fancyRpartPlot(modFit$finalModel)
pred <- predict(modFit,testing)
compare(pred,testing)
```

## Linear Discriminate Analysis

```{r}
modFit <- train(classe ~ ., data=training,method="lda")
pred <- predict(modFit,testing)
compare(pred,testing)
```


